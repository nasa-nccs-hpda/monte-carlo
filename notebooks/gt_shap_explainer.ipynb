{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remember to open terminal and run: conda activate ilab-tensorflow to import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/explore/nobackup/people/gtamkin/dev/AGB/mpf-model-factories/MultiPathFusion')\n",
    "from multi_path_fusion.src.utils.data_generator_helpers import load_data_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_feature_importances_shap_values(shap_values, features):\n",
    "    \n",
    "    '''\n",
    "    Prints the feature importances based on SHAP values in an ordered way\n",
    "    shap_values -> The SHAP values calculated from a shap.Explainer object\n",
    "    features -> The name of the features, on the order presented to the explainer\n",
    "    '''\n",
    "    \n",
    "    # Calculates the feature importance (mean absolute shap value) for each feature\n",
    "    importances = []\n",
    "    for i in range(shap_values.values.shape[1]):\n",
    "        importances.append(np.mean(np.abs(shap_values.values[:, i])))\n",
    "        \n",
    "    # Calculates the normalized version\n",
    "    importances_norm = softmax(importances)\n",
    "\n",
    "    # Organize the importances and columns in a dictionary\n",
    "    feature_importances = {fea: imp for imp, fea in zip(importances, features)}\n",
    "    feature_importances_norm = {fea: imp for imp, fea in zip(importances_norm, features)}\n",
    "\n",
    "    # Sorts the dictionary\n",
    "    feature_importances = {k: v for k, v in sorted(feature_importances.items(), key=lambda item: item[1], reverse = True)}\n",
    "    feature_importances_norm= {k: v for k, v in sorted(feature_importances_norm.items(), key=lambda item: item[1], reverse = True)}\n",
    "\n",
    "    # Prints the feature importances\n",
    "    for k, v in feature_importances.items():\n",
    "        print(f\"{k} -> {v:.4f} (softmax = {feature_importances_norm[k]:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_regression(y, y_pred):\n",
    "    \n",
    "    '''\n",
    "    Prints the most common evaluation metrics for regression\n",
    "    '''\n",
    "    \n",
    "    mae = MAE(y, y_pred)\n",
    "    mse = MSE(y, y_pred)\n",
    "    rmse = mse ** (1/2)\n",
    "    r2 = R2(y, y_pred)\n",
    "    \n",
    "    print('Regression result')\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"MSE: {mse:.2f}\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"R2: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywordAll = ['ARI', 'CAI', 'CRI550', 'CRI700', 'EVI', 'EVI2', 'fPAR', 'LAI', 'MCTI', 'MSI',\n",
    "                'NDII', 'NDLI', 'NDNI', 'NDVI', 'NDWI', 'NIRv', 'PRIn', 'PRIw', 'SAVI', 'WBI', 'Albedo']\n",
    "keyword7 = list()\n",
    "keyword7.append('PRIw')\n",
    "keyword7.append('NDVI')\n",
    "keyword7.append('MCTI')\n",
    "keyword7.append('CRI550')\n",
    "keyword7.append('WBI')\n",
    "keyword7.append('LAI')\n",
    "keyword7.append('MSI')\n",
    "keywordAllInt = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restore model() and test-generator() data [or just Explaniner/shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath = '/explore/nobackup/projects/ilab/data/AGB/test/mlruns/exp_7bands/12262023/MODELS/Exp_7bands_pickle::502671461260014182.keras'\n",
    "print('reloading model:', modelPath)\n",
    "model21 = tf.keras.models.load_model(modelPath)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restore test_generator() data using pickle. The test_generator() was saved cleanly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_test_generator_id = '/explore/nobackup/projects/ilab/data/AGB/test/mlruns/exp_7bands/12262023/TRIALS/Exp_7bands_pickle::502671461260014182.keras.test_generator.data'\n",
    "#archive_test_generator_id = archive_id + \"_test_generator.data\"\n",
    "#pickle.dump(test_generator, open(archive_test_generator_id, \"wb\"))\n",
    "test_generator_r = pickle.load(open(archive_test_generator_id, \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert test_generator.file_x_stack to Pandas dataframe and transpose for SHAP API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data=test_generator_r.file_x_stack)\n",
    "dft = df.transpose()\n",
    "X = X_test = dft\n",
    "print(df.shape, X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Use KernelExplainer to derive the shap values for ALL 21 bands as explained with first 50 test instances (rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer21 = shap.KernelExplainer(model21.predict, X.iloc[:50, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shap_values21_0to50 = explainer21.shap_values(X.iloc[0:50, :], nsamples=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print according to most in particular bin:  0 < -1.0, 1 < -0.5, 2 < 0, 3 < 0.5, 4 < 1.0\n",
    "print('bin value 0: [-1.0, -0.5]] = summary_plot(shap_values0to50[0]') \n",
    "shap.summary_plot(shap_values21_0to50[0], X.iloc[0:50, :], plot_type=\"bar\", feature_names=keywordAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print according to most in particular bin:  0 < -1.0, 1 < -0.5, 2 < 0, 3 < 0.5, 4 < 1.0\n",
    "print('bin value 0: [-1.0, -0.5]] = summary_plot(shap_values0to50[0]') \n",
    "shap.summary_plot(shap_values21_0to50, X.iloc[280:330, :], plot_type=\"bar\", feature_names=keywordAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values21_0to50, X, plot_type=\"bar\", feature_names=keywordAll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Use ExactExplainer is required for certain plots. Can not support 3D shap.values() but can handle a reduced Explanation object (sort of)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Explainer21 = shap.Explainer(model21.predict, X.iloc[:50, :])\n",
    "explanation21 = Explainer21(X.iloc[:50, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(explanation21.values.shape, explanation21.base_values.shape, explanation21.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp = shap.Explanation(explanation21)\n",
    "#e_shap_values = shap.Explanation(explanation21.values[0], base_values=explanation21.base_values, data=explanation21.data)\n",
    "e_shap_values = shap.Explanation(explanation21.values[0], base_values=explanation21.base_values)\n",
    "e_shap_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(e_shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(e_shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(e_shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(e_shap_values, plot_type='violin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prints the SHAP feature importances\n",
    "print_feature_importances_shap_values(e_shap_values, X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(e_shap_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(explanation21.values.shape, explanation21.base_values.shape, explanation21.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(explanation21.base_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(explainer21.expected_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_shap_values.values = explanation21.values[0][0]\n",
    "e_shap_values.base_values = explanation21.base_values[0]\n",
    "e_shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(explainer21.expected_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shap.plots.force(e_shap_values, shap_values21_0to50[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#shap.plots.waterfall(e_shap_values, max_display=10, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ...Try ExactExplainer to derive the shap values for ALL 21 bands as explained with ALL 1000x1000 test instances (rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fits the explainer\n",
    "explainerAll = shap.Explainer(model21.predict, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculates the SHAP values - It takes some time\n",
    "shap_valuesAll = explainerAll(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainerAll = shap.KernelExplainer(model21.predict, X.iloc[:50, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shap_values21_0to50 = explainer21.shap_values(X.iloc[0:50, :], nsamples=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values,feature_names=keywordAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See above.  In this call, we use the first 50 rows of the test-generator dataset as the background dataset.  Should be configurable.  QUESTION: Should this be train_generator instead (perhaps with K-means)\n",
    "explainer = shap.KernelExplainer(model.predict, X.iloc[:50, :])\n",
    "print(explainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save/restore KernelExplainer data using pickle().  Explainer saved cleanly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_explainer_id = archive_id + model_config.get(\"model_name\") + \"_kernel.explainer\"\n",
    "pickle.dump(explainer, open(archive_explainer_id, \"wb\"))\n",
    "explainer_r = pickle.load(open(archive_explainer_id, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = DeepDiff(explainer, explainer_r)\n",
    "pprint(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('KernelExplainer I/O: ')\n",
    "print('\\n Explainer -> features: ')\n",
    "print('data_feature_names', explainer.data_feature_names)\n",
    "print('len(expected_value)', len(explainer.expected_value))\n",
    "print('expected_value', explainer.expected_value)\n",
    "\n",
    "print('\\n Explainer_r -> features: ')\n",
    "print('data_feature_names', explainer_r.data_feature_names)\n",
    "print('len(expected_value)', len(explainer_r.expected_value))\n",
    "print('expected_value', explainer_r.expected_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_explainer_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the shap values for the first 50 rows in the test-generator dataset - based on 500 samples each (should be configurable)\n",
    "shap_values0to50 = explainer.shap_values(X.iloc[0:50, :], nsamples=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sshap_values0to50.shape() = (50, 7). - first 50 rows by 7 band columns\n",
    "# there are 5 rows of shape values because binning results in 5 classifications\n",
    "#print(len(shap_values0to50), shap_values0to50[0].shape , shap_values0to50[4][0].shape)\n",
    "lastShapRow = shap_values0to50[0][0]\n",
    "print(lastShapRow.shape, lastShapRow[0].max(), lastShapRow)\n",
    "sum(explainer_r.expected_value[0] - lastShapRow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandLen = 20\n",
    "\n",
    "bandOccurenceArr = np.zeros(bandLen)\n",
    "print(bandOccurenceArr)\n",
    "bandMaxArr = np.zeros(bandLen)\n",
    "bandMinArr = np.zeros(bandLen)\n",
    "bandMeanArr = np.zeros(bandLen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.explain_row(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#shap_values0to50 = explainer.shap_values(X.iloc[0:50, :], nsamples=500)\n",
    "shap_values_explanation = explainer(X.iloc[0:50, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(shap_values_explanation[0], shap_values_explanation[0].values[0][0],  shap_values_explanation[0].data[0])\n",
    "print(shap_values_explanation[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_delta = (shap_values_explanation.base_values[0] - shap_values_explanation.values[0])\n",
    "pprint(base_delta)\n",
    "col_totals = [ sum(x) for x in zip(*base_delta) ]\n",
    "pprint(col_totals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('expected_value', explainer_r.expected_value)\n",
    "print(' - expected_value', explainer_r.expected_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shap_values_explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.iloc[0:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_shap_values_explanation_id = archive_id + model_config.get(\"model_name\") + \"_shap.explanation\"\n",
    "pickle.dump(shap_values_explanation, open(archive_shap_values_explanation_id, \"wb\"))\n",
    "archive_shap_values_explanation_id_r = pickle.load(open(archive_shap_values_explanation_id, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = DeepDiff(shap_values_explanation, shap_values_explanation_id_r)\n",
    "pprint(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat logic using X_train instead of parts of X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = pd.DataFrame(data=train_generator.file_x_stack)\n",
    "dft = df.transpose()\n",
    "X_train = dft\n",
    "print(df.shape, X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See above.  In this call, we use the first 50 rows of the test-generator dataset as the background dataset.  Should be configurable.\n",
    "explainer_X_train = shap.KernelExplainer(model.predict, X_train)\n",
    "#explainer_X_train = shap.KernelExplainer(model.predict, X_train.iloc[:50, :])\n",
    "print(explainer_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values0to50_X_train = explainer.shap_values(X.iloc[0:50, :], nsamples=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model  \n",
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_accuracy(f):\n",
    "    print(\n",
    "        \"Root mean squared test error = {}\".format(\n",
    "            np.sqrt(np.mean((f(X_test) - y_test) ** 2))\n",
    "        )\n",
    "    )\n",
    "    time.sleep(0.5)  # to let the print get out before any progress bars\n",
    "\n",
    "\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data=test_generator.file_x_stack)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = df.transpose()\n",
    "dft.iloc[:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dft\n",
    "print(X.shape)\n",
    "print(X.shape[0])\n",
    "print(X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape[1])\n",
    "count = 0\n",
    "for i in range(X.shape[1]):\n",
    "    count = count + 1\n",
    "\n",
    "print(count)\n",
    "#print(X[:,count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print([X[:, i] for i in range(X.shape[1])])\n",
    "print(X.shape)\n",
    "print(X.iloc[:, :])\n",
    "print(X.iloc[:5, :])\n",
    "print(X.iloc[0, 0])\n",
    "print(X.iloc[3, 6])\n",
    "print(X.iloc[:3, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_predict2(X):\n",
    "    return model.predict([X[:, i] for i in range(X.shape[1])]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# load your data here, e.g. X and y\n",
    "# create and fit your model here\n",
    "\n",
    "# load JS visualization code to notebook\n",
    "shap.initjs()\n",
    "print(model.summary())\n",
    "\n",
    "# explain the model's predictions using SHAP\n",
    "# (same syntax works for LightGBM, CatBoost, scikit-learn and spark models)\n",
    "explainer = shap.KernelExplainer(model.predict, X.iloc[:50, :])\n",
    "#explainer = shap.KernelExplainer(my_predict2, X.iloc[:2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X.iloc[:50, :])\n",
    "shap_values = explainer.shap_values(X.iloc[299, :], nsamples=500)\n",
    "shap_values2 = explainer.shap_values(X.iloc[299, :], nsamples=500)\n",
    "print('shap_values: '+ str(len(shap_values)))\n",
    "print(shap_values)\n",
    "print('shap_values2: '+ str(len(shap_values2)))\n",
    "print(shap_values2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.iloc[299, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values[0].tofile('./mlruns/shap1.shap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values0 = np.fromfile('./mlruns/shap1.shap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_generator.file_x_stack.shape, train_generator.file_x_stack[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(shap_values[0], sum(shap_values[0]))\n",
    "print(shap_values0, sum(shap_values0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(explainer.fx, sum(explainer.fx))\n",
    "print(explainer.expected_value, sum(explainer.expected_value))\n",
    "diff = explainer.fx - explainer.expected_value\n",
    "print(diff, sum(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding = 3\n",
    "bandList = data_generator_config['branch_inputs'][0]['branch_files'][0]['bands']\n",
    "bandList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandRootDir = '/explore/nobackup/projects/ilab/data/AGB/test/mlruns/12122023-7b/BANDS'\n",
    "hyperspectralIndicesFile = data_generator_config['branch_inputs'][0]['branch_files'][0]['mlbs_year_filepath'] \n",
    "print(hyperspectralIndicesFile)\n",
    "hpath, hname = hyperspectralIndicesFile.split('/',1)\n",
    "hprefix, hsuffix = hname.split('.',1)\n",
    "print(bandRootDir, hpath, hprefix)\n",
    "newPath = os.path.join(bandRootDir, hpath)\n",
    "print(newPath)\n",
    "if (not os.path.exists(newPath)): os.makedirs(newPath)\n",
    "\n",
    "# Write out bands\n",
    "for i in range(len(bandList)):\n",
    "    newPathFile = os.path.join(newPath, hprefix+'_band'+str(bandList[i]).zfill(padding)+'.band')\n",
    "    print(i, str(bandList[i]).zfill(padding), newPathFile, train_generator.file_x_stack[i].dtype, train_generator.file_x_stack[i].shape, train_generator.file_x_stack[i].min())\n",
    "    train_generator.file_x_stack[i].tofile(newPathFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in bands\n",
    "for i in range(len(bandList)):\n",
    "    existingBandFile = os.path.join(newPath, hprefix+'_band'+str(bandList[i]).zfill(padding)+'.band')\n",
    "    bandValues = np.fromfile(existingBandFile)\n",
    "    print(existingBandFile, bandValues.dtype, bandValues.shape, bandValues.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.file_x_stack[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.file_x_stack[1].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import TemporaryFile\n",
    "outfile = TemporaryFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band018 = train_generator.file_x_stack[0]\n",
    "band014 = train_generator.file_x_stack[1]\n",
    "band009 = train_generator.file_x_stack[2]\n",
    "band003 = train_generator.file_x_stack[3]\n",
    "band020 = train_generator.file_x_stack[4]\n",
    "band008 = train_generator.file_x_stack[5]\n",
    "band010 = train_generator.file_x_stack[6]\n",
    "print(band018, band018.dtype, band018.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(outfile, band018=band018, band014=band014, band009=band009, band003=band003, band020=band020, band008=band008, band010=band010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = outfile.seek(0)\n",
    "print(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npzfile = np.load(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npzfile.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(band018, band018.dtype, band018.shape, band018.max())\n",
    "print(npzfile['band018'], npzfile['band018'].dtype, npzfile['band018'].shape, npzfile['band018'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import TemporaryFile\n",
    "band018file = TemporaryFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(band018file, train_generator.file_x_stack[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = band018file.seek(0)\n",
    "b18 = np.load(band018file)\n",
    "print(b18, b18.dtype, b18.shape, b18.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.expected_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.expected_value[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1    Index Name=ARI\n",
    "#2    Index Name=CAI\n",
    "#3    Index Name=CRI550\n",
    "#4    Index Name=CRI700\n",
    "#5    Index Name=EVI\n",
    "#6    Index Name=EVI2\n",
    "#7    Index Name=fPAR\n",
    "#8    Index Name=LAI\n",
    "#9    Index Name=MCTI\n",
    "#10    Index Name=MSI\n",
    "#11   Index Name=NDII\n",
    "#12    Index Name=NDLI\n",
    "#13    Index Name=NDNI\n",
    "#14    Index Name=NDVI\n",
    "#15    Index Name=NDWI\n",
    "#16    Index Name=NIRv\n",
    "#17    Index Name=PRIn\n",
    "#18    Index Name=PRIw\n",
    "#19    Index Name=SAVI\n",
    "#20    Index Name=WBI\n",
    "#21    Index Name=Albedo\n",
    "\n",
    "#        \"bands\": [18, 14, 9, 3, 20, 8, 10]}]\n",
    "    \n",
    "keyword = list()\n",
    "keyword.append('PRIw')\n",
    "keyword.append('NDVI')\n",
    "keyword.append('MCTI')\n",
    "keyword.append('CRI550')\n",
    "keyword.append('WBI')\n",
    "keyword.append('LAI')\n",
    "keyword.append('MSI')\n",
    "print(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0\n",
    "while x < 5:\n",
    "    diff = explainer.expected_value[x] - shap_values[x]\n",
    "    print(\"explainer.expected_value[x] where x = \" + str(x))\n",
    "    print(explainer.expected_value[x], shap_values[x], diff, \n",
    "      diff.min(), diff.max())\n",
    "    x = x + 1\n",
    "print(x)\n",
    "print(explainer.expected_value, sum(explainer.expected_value))\n",
    "print(explainer.fx, sum(explainer.fx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rather than use the whole training set to estimate expected values, we summarize with\n",
    "# a set of weighted kmeans, each weighted by the number of points they represent.\n",
    "#X_test_kmeans_summary = shap.kmeans(X, 1000)\n",
    "#print(X_test_kmeans_summary[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_test_kmeans_summary[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('shap_values: ' + str(len(shap_values)), shap_values)\n",
    "print('shap_values2: '+ str(len(shap_values2)), shap_values2)\n",
    "shap_values999 = explainer.shap_values(X.iloc[999, :], nsamples=500)\n",
    "print('shap_values999: '+ str(len(shap_values999)), shap_values999)\n",
    "shap_values999b = explainer.shap_values(X.iloc[999, :], nsamples=500)\n",
    "print('shap_values999b: '+ str(len(shap_values999b)), shap_values999b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shap.summary_plot(shap_values, X.iloc[0, :], plot_type=\"bar\", feature_names=keyword)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the first prediction's explanation (use matplotlib=True to avoid Javascript)\n",
    "#shap.force_plot(explainer.expected_value[0], shap_values[0], X.iloc[299, :])\n",
    "shap.force_plot(explainer.expected_value[0], shap_values[0], keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value[1], shap_values[1], keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value[2], shap_values[2], keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value[3], shap_values[3], keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value[4], shap_values[4], keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shap.force_plot(explainer.expected_value[5], shap_values[5], X.iloc[299, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values50 = explainer.shap_values(X.iloc[280:330, :], nsamples=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value[0], shap_values50[0], X.iloc[280:330, :],feature_names=keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value[4], shap_values50[4], X.iloc[280:330, :],feature_names=keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values50[0], X.iloc[280:330, :], plot_type=\"bar\", feature_names=keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values50[2], X, plot_type=\"bar\", feature_names=keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values50[4], X.iloc[280:330, :], plot_type=\"bar\", feature_names=keyword)\n",
    "print('shap_values50[4]: ', shap_values50[4].shape, shap_values50[4].sum(), shap_values50[4].min(), shap_values50[4].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shap_values11 = explainer.shap_values(X.iloc[88888:88899, :], nsamples=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values11[0], X.iloc[280:291, :], plot_type=\"bar\", feature_names=keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(shap_values, shap_values50, shap_values11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_abs = np.abs(shap_values)\n",
    "#shap_values_abs = np.abs(shap_values50)\n",
    "shap_values_abs_sum = np.sum(shap_values_abs, axis=0)\n",
    "shap_values_abs_sum_argsort = np.argsort(shap_values_abs_sum)\n",
    "print(shap_values_abs, shap_values_abs_sum, shap_values_abs_sum_argsort)\n",
    "feature_order = np.argsort(np.sum(np.abs(shap_values), axis=0))\n",
    "print('\\n', feature_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1, 2, 3, 4, 5, 6, -7], [1, 2, 3, 4, 5, 6, 7], [1, 2, 3, 4, 5, 6, 7], [1, 2, 3, 4, 5, 6, 7], [1, 2, 3, 4, 5, 6, 7], [1, 2, 3, 4, 5, 6, 7]]\n",
    "nd_a = np.array(a)\n",
    "\n",
    "#shap_values = nd_a\n",
    "shap_values_abs = np.abs(shap_values)\n",
    "#shap_values_abs = np.abs(shap_values50)\n",
    "shap_values_abs_sum = np.sum(shap_values_abs, axis=0)\n",
    "shap_values_abs_sum_argsort = np.argsort(shap_values_abs_sum)\n",
    "print(\"\\nshap_values: (shap_values)\\n\", shap_values, shap_values.dtype, shap_values.shape, \"\\nshap_values_abs: np.abs(shap_values)\\n\", shap_values_abs, \n",
    "      \"\\nshap_values_abs_sum: np.sum(shap_values_abs, axis=0)\\n\", shap_values_abs_sum, \"\\nshap_values_abs_sum_argsort: np.argsort(shap_values_abs_sum)\\n\", shap_values_abs_sum_argsort)\n",
    "feature_order = np.argsort(np.sum(np.abs(shap_values), axis=0))\n",
    "print('\\nfeature_order:', feature_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shap.values[00,7)\n",
    "shap00_list = [-0.00537375,  0.01205069,  0.04364897,  0.00142398, -0.00139138, -0.08626259,  0.01085853]\n",
    "shap00_array = np.array(shap00_list)\n",
    "print(shap00_array.dtype, shap00_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.array([[-9.,11.,-21.,63.,-252.],[3891.,506.,-1008.,3031.,-12117.],[3891.,576.,-1149.,3451.,-13801.],[3891.,-3891.,7782.,-23345.,93365.],[1024.,-1024.,2049.,-6144.,24572.]])\n",
    "x = np.abs(B).argmax(axis=0)[0]\n",
    "print(B, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_abs = np.abs(shap_values)\n",
    "#shap_values_abs = np.abs(shap_values50)\n",
    "shap_values_abs_sum = np.sum(shap_values_abs, axis=0)\n",
    "shap_values_abs_sum_argsort = np.argsort(shap_values_abs_sum)\n",
    "print(shap_values, shap_values_abs, shap_values_abs_sum, shap_values_abs_sum_argsort)\n",
    "feature_order = np.argsort(np.sum(np.abs(shap_values), axis=0))\n",
    "print('\\n', feature_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values50[3], X.iloc[280:330, :], plot_type=\"bar\", feature_names=keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values50, X, plot_type=\"bar\", feature_names=keyword)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ILAB Kernel (TensorFlow)",
   "language": "python",
   "name": "tensorflow-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
